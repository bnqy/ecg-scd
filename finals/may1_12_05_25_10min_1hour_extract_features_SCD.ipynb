{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd80b8a5-75a7-4912-9393-d2f987b9c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.signal import medfilt\n",
    "import pywt\n",
    "from ecgdetectors import Detectors\n",
    "from scipy.signal import resample_poly\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1467cbc-a36a-4604-bd0f-0906b08e578e",
   "metadata": {},
   "source": [
    "# SCD DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c7eb5c-07ce-48de-a69a-ebe8971e938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scd_data = {\n",
    "     './data/scddb/30': '07:54:33',\n",
    "     './data/scddb/31': '13:42:24',\n",
    "     './data/scddb/32': '16:45:18',\n",
    "     './data/scddb/33': '04:46:19',\n",
    "     './data/scddb/34': '06:35:44',\n",
    "     './data/scddb/35': '24:34:56',\n",
    "     './data/scddb/36': '18:59:01',\n",
    "     './data/scddb/37': '01:31:13',\n",
    "     './data/scddb/38': '08:01:54',\n",
    "     './data/scddb/39': '04:37:51',\n",
    "     #'./data/scddb/40': '00:00:00', # paced, no VF\n",
    "     './data/scddb/41': '02:59:24', # not working properly\n",
    "     #'./data/scddb/42': '00:00:00', # no VF\n",
    "     './data/scddb/43': '15:37:11',\n",
    "     './data/scddb/44': '19:38:45',\n",
    "     './data/scddb/45': '18:09:17',\n",
    "     './data/scddb/46': '03:41:47',\n",
    "     './data/scddb/47': '06:13:01',\n",
    "     './data/scddb/48': '02:29:40',\n",
    "     #'./data/scddb/49': '00:00:00', # paced, no VF\n",
    "     './data/scddb/50': '11:45:43',\n",
    "     './data/scddb/51': '22:58:23',\n",
    "     './data/scddb/52': '02:32:40' # not working properly\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ed4a3a5-e31e-433d-a19e-bc2239f79e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H:M:S to seconds\n",
    "def hms_to_seconds(hms):\n",
    "    h, m, s = hms.split(':')\n",
    "    return int(h)*3600 + int(m)*60 + int(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86a8ff4d-b27b-4d1f-98ca-822ff603816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_before_onset_VF(vfon_dict, minutes_before=60, fs=250):\n",
    "    ecg_data_map = {} \n",
    "\n",
    "    for record_path, vf_onset_str in vfon_dict.items():\n",
    "        # record_path might be '.data/scddb/30'\n",
    "        record_dir, record_name = os.path.split(record_path)\n",
    "\n",
    "        # 2) Convert dictionary's VF onset to seconds\n",
    "        vf_onset_original_sec = hms_to_seconds(vf_onset_str)\n",
    "\n",
    "        vfon_onset_original_sample = vf_onset_original_sec * fs\n",
    "\n",
    "        seg_len_samples = int(minutes_before * 60 * fs)\n",
    "\n",
    "        start_sample = vfon_onset_original_sample - seg_len_samples\n",
    "\n",
    "         # read .dat between those sample indices\n",
    "        try:\n",
    "            #record_dat_path = os.path.join(record_dir, record_name)  # base path\n",
    "            record_path_dat = os.path.join(record_dir, record_name)\n",
    "            segment = wfdb.rdrecord(record_path_dat, sampfrom=start_sample, sampto=vfon_onset_original_sample)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to read record {record_dat_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Retrieve the raw signal data as a NumPy array\n",
    "        if segment.p_signal is not None:\n",
    "            arr = segment.p_signal[:,0]\n",
    "            ecg_data_map[record_name] = arr\n",
    "            print(f\"[OK] Extracted 60-min for {record_name}: shape={arr.shape}\")\n",
    "        else:\n",
    "            print(f\"[WARNING] No p_signal found for {record_name}\")\n",
    "\n",
    "    return ecg_data_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07f70b1f-d95e-469e-9382-549bfbc74b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_ecg(ecg_segment, segment_duration_sec=600, fs=250):\n",
    "    samples_per_segment = segment_duration_sec * fs\n",
    "    segments = np.array_split(ecg_segment, len(ecg_segment) // samples_per_segment)\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c24937d2-e95c-43ad-9a00-e826e5f7a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_ecg(ecg_signal, orig_fs, target_fs):\n",
    "    \"\"\"\n",
    "    Resample ECG signal from orig_fs to target_fs using polyphase filtering.\n",
    "    ecg_signal: 1D (or 2D) numpy array (samples x channels)\n",
    "    \"\"\"\n",
    "    # For example, if orig_fs=250, target_fs=128:\n",
    "    # up = 128, down = 250\n",
    "    up = target_fs\n",
    "    down = orig_fs\n",
    "\n",
    "    if ecg_signal.ndim == 1:\n",
    "        ecg_resampled = resample_poly(ecg_signal, up, down)\n",
    "    else:\n",
    "        # If multi-channel, resample each column\n",
    "        ecg_resampled = np.array([\n",
    "            resample_poly(ecg_signal[:, ch], up, down) \n",
    "            for ch in range(ecg_signal.shape[1])\n",
    "        ]).T\n",
    "\n",
    "    return ecg_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047efe3f-d9d2-4425-9fa9-80ac281f25b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ce898dd-b2b1-4705-950f-f4b4ad34ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_signal(X, dwt_transform, dlevels, cutoff_low, cutoff_high):\n",
    "    coeffs = pywt.wavedec(X, dwt_transform, level=dlevels)   # wavelet transform 'bior4.4'\n",
    "    # scale 0 to cutoff_low \n",
    "    for ca in range(0,cutoff_low):\n",
    "        coeffs[ca]=np.multiply(coeffs[ca],[0.0])\n",
    "    # scale cutoff_high to end\n",
    "    for ca in range(cutoff_high, len(coeffs)):\n",
    "        coeffs[ca]=np.multiply(coeffs[ca],[0.0])\n",
    "    Y = pywt.waverec(coeffs, dwt_transform) # inverse wavelet transform\n",
    "    return Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10486688-654e-453a-8e50-0c011b1c425f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79e27aa-75c2-48ff-8c26-a86a3a28fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_peak_finder(ecg_sig):\n",
    "    BASIC_SRATE = 128\n",
    "    signal_pad_samples = 10\n",
    "    signal_pad = np.zeros(signal_pad_samples)  # Pad to help detect early peaks\n",
    "    scd_30_denoised_ = ...  # Your denoised 30-min ECG segment\n",
    "    \n",
    "    # Initialize the detectors at the given sampling rate\n",
    "    detector_obj = Detectors(BASIC_SRATE)\n",
    "    \n",
    "    # Dictionary of detector functions\n",
    "    detectors = {\n",
    "        'pan_tompkins_detector': detector_obj.pan_tompkins_detector,\n",
    "        'hamilton_detector': detector_obj.hamilton_detector,\n",
    "        'christov_detector': detector_obj.christov_detector,\n",
    "        'engzee_detector': detector_obj.engzee_detector,\n",
    "        'swt_detector': detector_obj.swt_detector,\n",
    "        'two_average_detector': detector_obj.two_average_detector,\n",
    "    }\n",
    "    \n",
    "    r_peaks = np.array(detector_obj.swt_detector(np.hstack((signal_pad, ecg_sig)) )) - signal_pad_samples\n",
    "    return r_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81961537-7fc8-49b4-b491-6207a33b01b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hrv_features(r_peaks, fs=128):\n",
    "    \"\"\"\n",
    "    Time-domain HRV features from R-peaks.\n",
    "    Returns a dict with:\n",
    "      MeanRR, RMSDD, pNN50, SDRR, CVRR, NN50, MinRR, MaxRR\n",
    "    \"\"\"\n",
    "    features = {\n",
    "        'MeanRR': 0.0,\n",
    "        'RMSDD': 0.0,\n",
    "        'MADRR': 0.0,\n",
    "        'MCVNN': 0.0,\n",
    "        'pNN20': 0.0,\n",
    "        'pNN50': 0.0,\n",
    "        'SDRR': 0.0,\n",
    "        'CVRR': 0.0,\n",
    "        'NN20': 0,\n",
    "        'NN50': 0,\n",
    "        'MinRR': 0.0,\n",
    "        'MaxRR': 0.0\n",
    "    }\n",
    "\n",
    "    rr_samples = np.diff(r_peaks)\n",
    "    rr_ms = (rr_samples / fs) * 1000.0  # convert to ms\n",
    "\n",
    "    mean_rr = np.mean(rr_ms)\n",
    "    sdrr = np.std(rr_ms, ddof=1) if len(rr_ms) > 1 else 0.0\n",
    "    min_rr = np.min(rr_ms)\n",
    "    max_rr = np.max(rr_ms)\n",
    "\n",
    "    rr_diffs = np.diff(rr_ms)\n",
    "    rmssd = np.sqrt(np.mean(rr_diffs**2)) if len(rr_diffs) > 0 else 0.0\n",
    "    nn50 = np.sum(np.abs(rr_diffs) > 50)\n",
    "    pnn50 = (nn50 / len(rr_diffs)) * 100 if len(rr_diffs) > 0 else 0.0\n",
    "    nn20 = np.sum(np.abs(rr_diffs) > 20)\n",
    "    pnn20 = (nn20 / len(rr_diffs)) * 100 if len(rr_diffs) > 0 else 0.0\n",
    "    cvrr = (sdrr / mean_rr * 100.0) if mean_rr else 0.0\n",
    "    madrr = np.median(np.abs(rr_ms - np.median(rr_ms)))\n",
    "    mcvnn = np.abs(rr_samples).mean()\n",
    "\n",
    "    features['MeanRR'] = mean_rr / 1000.0\n",
    "    features['RMSDD'] = rmssd / 1000.0\n",
    "    # new \n",
    "    features['MADRR'] = madrr / 1000.0\n",
    "    features['MCVNN'] = mcvnn / 1000.0 \n",
    "    features['pNN20'] = pnn20 / 1000.0\n",
    "    \n",
    "    \n",
    "    features['pNN50'] = pnn50 / 1000.0\n",
    "    features['SDRR'] = sdrr / 1000.0\n",
    "    features['CVRR'] = cvrr / 1000.0 \n",
    "    # new\n",
    "    features['NN20'] = nn20 / 1000.0\n",
    "    \n",
    "    features['NN50'] = nn50 / 1000.0\n",
    "    features['MinRR'] = min_rr / 1000.0 \n",
    "    features['MaxRR'] = max_rr / 1000.0\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a65dd-f887-4ad8-af84-bbdf556111d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = [\"First\", \"Second\", \"Third\", \"Fourth\", \"Fifth\", \"Sixth\"]\n",
    "\n",
    "def save_hrv_to_csv(features_dict, csv_path):\n",
    "    \"\"\"\n",
    "    Save a single row of features_dict into a CSV at csv_path.\n",
    "    Overwrites if file exists.\n",
    "    Columns: [MeanRR, RMSDD, MADRR, MCVNN, pNN20, pNN50, SDRR, CVRR, NN20, NN50, MinRR, MaxRR]\n",
    "    \"\"\"\n",
    "    columns = [\"MeanRR\", \"RMSDD\", \"MADRR\", \"MCVNN\", \"pNN20\", \"pNN50\", \"SDRR\", \"CVRR\", \"NN20\", \"NN50\", \"MinRR\", \"MaxRR\"]\n",
    "    with open(csv_path, mode='w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=columns)\n",
    "        writer.writeheader()\n",
    "        writer.writerow({col: features_dict[col] for col in columns})\n",
    "    print(f\"  -> Saved HRV features to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa068ce1-2363-43b8-8121-135334916414",
   "metadata": {},
   "outputs": [],
   "source": [
    "onsetVF_60min_scd = extract_before_onset_VF(scd_data, minutes_before=60, fs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09d3319-7e37-4ad3-ba0e-19e28bf25fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(onsetVF_60min_scd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819efb11-2863-4c73-8b66-282a855f5bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "scd_segments = {}\n",
    "for key, value in onsetVF_60min_scd.items():\n",
    "    scd_segments[key] = segment_ecg(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c56e18-74c0-41ff-8ff4-2ed08f52aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scd_segments['30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8401860-6578-4638-9165-ff011af70bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_scd = \"SCD_Features_CSV_1h_10min_segments\"\n",
    "os.makedirs(output_dir_scd, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8589401c-955f-413b-884d-4c91fb485328",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for subj_id, seg_list in scd_segments.items():\n",
    "    print(f\"\\nProcessing SCD subject {subj_id}...\")\n",
    "    # seg_list[0] = earliest, seg_list[5] = last\n",
    "    # We want to label them in REVERSE order:\n",
    "    #   i=0 => seg_list[5], name: \"First 5 mins before SCD\"\n",
    "    #   i=1 => seg_list[4], name: \"Second 5 mins before SCD\"\n",
    "    #   ...\n",
    "    #   i=5 => seg_list[0], name: \"Sixth 5 mins before SCD\"\n",
    "    for i in range(6):\n",
    "        segment_idx = 5 - i  # reversed index\n",
    "        segment_label = f\"SCD_{subj_id}_{label_map[i]}_10_mins_before_SCD\"  # e.g. \"First_5_mins_before_SCD\"\n",
    "        ecg_signal = seg_list[segment_idx]\n",
    "\n",
    "\n",
    "        downsampled = resample_ecg(ecg_signal, 250, 128)\n",
    "        denoised_signal = denoise_signal(downsampled, 'sym20', 8, -5 , 5)\n",
    "\n",
    "            \n",
    "        # 1) Detect R-peaks\n",
    "        r_peaks = r_peak_finder(denoised_signal)\n",
    "        \n",
    "        # 2) Compute HRV\n",
    "        feats = compute_hrv_features(r_peaks, fs=128)\n",
    "        # 3) Build CSV file name, e.g. \"SCD_SubjectA_First_5_mins_before_SCD.csv\"\n",
    "        csv_filename = f\"{segment_label}.csv\"\n",
    "        csv_path = os.path.join(output_dir_scd, csv_filename)\n",
    "        # 4) Save\n",
    "        save_hrv_to_csv(feats, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b03173c-54ae-4898-abf9-4862bda4fb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
