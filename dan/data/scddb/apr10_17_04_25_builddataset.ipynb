{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad2a387b-9cf8-4862-875e-0cb49b13a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.signal import medfilt\n",
    "import pywt\n",
    "from ecgdetectors import Detectors\n",
    "from scipy.signal import resample_poly\n",
    "import csv\n",
    "\n",
    "nsr_data = ['./data/nsrdb/16265',\n",
    " './data/nsrdb/16272',\n",
    " './data/nsrdb/16273',\n",
    " './data/nsrdb/16420',\n",
    " './data/nsrdb/16483',\n",
    " './data/nsrdb/16539',\n",
    " './data/nsrdb/16773',\n",
    " './data/nsrdb/16786',\n",
    " './data/nsrdb/16795',\n",
    " './data/nsrdb/17052',\n",
    " './data/nsrdb/17453',\n",
    " './data/nsrdb/18177',\n",
    " './data/nsrdb/18184',\n",
    " './data/nsrdb/19088',\n",
    " './data/nsrdb/19090',\n",
    " './data/nsrdb/19093',\n",
    " './data/nsrdb/19140',\n",
    " './data/nsrdb/19830']\n",
    "\n",
    "def extract_first_30min_and_segment(record_paths):\n",
    "    \"\"\"\n",
    "    Given a list of NSR record paths (e.g. './data/nsrdb/16265'),\n",
    "    1) Read the first 30 minutes of the ECG from each record\n",
    "    2) Segment that 30-min signal into six 5-min parts\n",
    "    3) Return a dictionary mapping record_name -> [segment1, segment2, ... segment6]\n",
    "       Each segment is a NumPy array of shape (num_samples_5min, num_channels).\n",
    "    \"\"\"\n",
    "    \n",
    "    # For 30 min, we have 30 * 60 = 1800 seconds. \n",
    "    # For 5 min, we have 5 * 60 = 300 seconds.\n",
    "    \n",
    "    first_30min_segments = {}\n",
    "    \n",
    "    for record_path in record_paths:\n",
    "        \n",
    "        # Extract record name from path\n",
    "        # e.g. record_path = \"./data/nsrdb/16265\" => record_name = \"16265\"\n",
    "        record_dir, record_name = os.path.split(record_path)\n",
    "      \n",
    "        print(f\"Processing {record_name} ...\")\n",
    "        \n",
    "        # We want the first 30 minutes => 1800 seconds => num_samples = 1800 * fs\n",
    "        fs = 128\n",
    "        num_samples_30min = int(30 * 60 * fs)\n",
    "        \n",
    "        # Read from sample 0 to sample 0+num_samples_30min\n",
    "        try:\n",
    "            rec = wfdb.rdrecord(record_path, sampfrom=0, sampto=num_samples_30min)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not read {record_path}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if rec.p_signal is None:\n",
    "            print(f\"[WARN] No signal found in {record_name}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        full_30min = rec.p_signal[:,0]\n",
    "        \n",
    "        # Segment the 30-min array into six 5-min parts\n",
    "        # Each 5-min part = 5 * 60 * fs samples\n",
    "        \n",
    "        samples_5min = int(5 * 60 * fs)  # 300 seconds * 128 => 38400\n",
    "        \n",
    "        # We can slice in 6 equal blocks\n",
    "        segments_5min = []\n",
    "        for i in range(6):\n",
    "            start_i = i * samples_5min\n",
    "            end_i = start_i + samples_5min\n",
    "            segment = full_30min[start_i:end_i]\n",
    "            segments_5min.append(segment)\n",
    "        \n",
    "        # Store in a dictionary\n",
    "        first_30min_segments[record_name] = segments_5min\n",
    "        print(f\"[OK] Extracted 6 segments of 5 min each from {record_name}.\")\n",
    "    \n",
    "    return first_30min_segments\n",
    "\n",
    "\n",
    "def denoise_signal(X, dwt_transform, dlevels, cutoff_low, cutoff_high):\n",
    "    coeffs = pywt.wavedec(X, dwt_transform, level=dlevels)   # wavelet transform 'bior4.4'\n",
    "    # scale 0 to cutoff_low \n",
    "    for ca in range(0,cutoff_low):\n",
    "        coeffs[ca]=np.multiply(coeffs[ca],[0.0])\n",
    "    # scale cutoff_high to end\n",
    "    for ca in range(cutoff_high, len(coeffs)):\n",
    "        coeffs[ca]=np.multiply(coeffs[ca],[0.0])\n",
    "    Y = pywt.waverec(coeffs, dwt_transform) # inverse wavelet transform\n",
    "    return Y  \n",
    "\n",
    "\n",
    "def r_peak_finder(ecg_sig):\n",
    "    BASIC_SRATE = 128\n",
    "    signal_pad_samples = 10\n",
    "    signal_pad = np.zeros(signal_pad_samples)  # Pad to help detect early peaks\n",
    "    scd_30_denoised_ = ...  # Your denoised 30-min ECG segment\n",
    "    \n",
    "    # Initialize the detectors at the given sampling rate\n",
    "    detector_obj = Detectors(BASIC_SRATE)\n",
    "    \n",
    "    # Dictionary of detector functions\n",
    "    detectors = {\n",
    "        'pan_tompkins_detector': detector_obj.pan_tompkins_detector,\n",
    "        'hamilton_detector': detector_obj.hamilton_detector,\n",
    "        'christov_detector': detector_obj.christov_detector,\n",
    "        'engzee_detector': detector_obj.engzee_detector,\n",
    "        'swt_detector': detector_obj.swt_detector,\n",
    "        'two_average_detector': detector_obj.two_average_detector,\n",
    "    }\n",
    "    \n",
    "    r_peaks = np.array(detector_obj.engzee_detector(np.hstack((signal_pad, ecg_sig)) )) - signal_pad_samples\n",
    "    return r_peaks\n",
    "\n",
    "\n",
    "def compute_hrv_features(r_peaks, fs=128):\n",
    "    \"\"\"\n",
    "    Time-domain HRV features from R-peaks.\n",
    "    Returns a dict with:\n",
    "      MeanRR, RMSDD, pNN50, SDRR, CVRR, NN50, MinRR, MaxRR\n",
    "    \"\"\"\n",
    "    features = {\n",
    "        'MeanRR': 0.0,\n",
    "        'RMSDD': 0.0,\n",
    "        'pNN50': 0.0,\n",
    "        'SDRR': 0.0,\n",
    "        'CVRR': 0.0,\n",
    "        'NN50': 0,\n",
    "        'MinRR': 0.0,\n",
    "        'MaxRR': 0.0\n",
    "    }\n",
    "\n",
    "    rr_samples = np.diff(r_peaks)\n",
    "    rr_ms = (rr_samples / fs) * 1000.0  # convert to ms\n",
    "\n",
    "    mean_rr = np.mean(rr_ms)\n",
    "    sdrr = np.std(rr_ms, ddof=1) if len(rr_ms) > 1 else 0.0\n",
    "    min_rr = np.min(rr_ms)\n",
    "    max_rr = np.max(rr_ms)\n",
    "\n",
    "    rr_diffs = np.diff(rr_ms)\n",
    "    rmssd = np.sqrt(np.mean(rr_diffs**2)) if len(rr_diffs) > 0 else 0.0\n",
    "    nn50 = np.sum(np.abs(rr_diffs) > 50)\n",
    "    pnn50 = (nn50 / len(rr_diffs)) * 100 if len(rr_diffs) > 0 else 0.0\n",
    "\n",
    "    cvrr = (sdrr / mean_rr * 100.0) if mean_rr else 0.0\n",
    "\n",
    "    features['MeanRR'] = mean_rr / 1000.0\n",
    "    features['RMSDD'] = rmssd / 1000.0\n",
    "    features['pNN50'] = pnn50 / 1000.0\n",
    "    features['SDRR'] = sdrr / 1000.0\n",
    "    features['CVRR'] = cvrr / 1000.0 \n",
    "    features['NN50'] = nn50 / 1000.0\n",
    "    features['MinRR'] = min_rr / 1000.0 \n",
    "    features['MaxRR'] = max_rr / 1000.0\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84641033-93b0-4442-91d3-e5605ebeb748",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = [\"First\", \"Second\", \"Third\", \"Fourth\", \"Fifth\", \"Sixth\"]\n",
    "\n",
    "def save_hrv_to_csv(features_dict, csv_path):\n",
    "    \"\"\"\n",
    "    Save a single row of features_dict into a CSV at csv_path.\n",
    "    Overwrites if file exists.\n",
    "    Columns: [MeanRR, RMSDD, pNN50, SDRR, CVRR, NN50, MinRR, MaxRR]\n",
    "    \"\"\"\n",
    "    columns = [\"MeanRR\", \"RMSDD\", \"pNN50\", \"SDRR\", \"CVRR\", \"NN50\", \"MinRR\", \"MaxRR\"]\n",
    "    with open(csv_path, mode='w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=columns)\n",
    "        writer.writeheader()\n",
    "        writer.writerow({col: features_dict[col] for col in columns})\n",
    "    print(f\"  -> Saved HRV features to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fd948fb-775c-4fa7-8050-26a1654d174e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 16265 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 16265.\n",
      "Processing 16272 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 16272.\n",
      "Processing 16273 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 16273.\n",
      "Processing 16420 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 16420.\n",
      "Processing 16483 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 16483.\n",
      "Processing 16539 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 16539.\n",
      "Processing 16773 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 16773.\n",
      "Processing 16786 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 16786.\n",
      "Processing 16795 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 16795.\n",
      "Processing 17052 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 17052.\n",
      "Processing 17453 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 17453.\n",
      "Processing 18177 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 18177.\n",
      "Processing 18184 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 18184.\n",
      "Processing 19088 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 19088.\n",
      "Processing 19090 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 19090.\n",
      "Processing 19093 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 19093.\n",
      "Processing 19140 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 19140.\n",
      "Processing 19830 ...\n",
      "[OK] Extracted 6 segments of 5 min each from 19830.\n"
     ]
    }
   ],
   "source": [
    "nsr_segments  = extract_first_30min_and_segment(nsr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d6c902-c357-42eb-9f89-9f9d99f8eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_nsr = \"NSR_Features_CSV_17apr\"\n",
    "os.makedirs(output_dir_nsr, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c810c6be-9819-499f-ae9a-96fc165fa14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing NSR subject 16265...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16265_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16265_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16265_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16265_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16265_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16265_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 16272...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16272_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16272_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16272_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16272_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16272_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16272_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 16273...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16273_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16273_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16273_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16273_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16273_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16273_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 16420...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16420_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16420_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16420_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16420_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16420_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16420_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 16483...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16483_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16483_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16483_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16483_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16483_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16483_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 16539...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16539_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16539_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16539_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16539_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16539_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16539_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 16773...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16773_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16773_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16773_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16773_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16773_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16773_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 16786...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16786_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16786_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16786_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16786_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16786_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16786_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 16795...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16795_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16795_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16795_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16795_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16795_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_16795_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 17052...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_17052_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_17052_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_17052_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_17052_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_17052_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_17052_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 17453...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_17453_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_17453_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_17453_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_17453_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_17453_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_17453_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 18177...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_18177_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_18177_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_18177_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_18177_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_18177_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_18177_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 18184...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_18184_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_18184_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_18184_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_18184_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_18184_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_18184_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 19088...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19088_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19088_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19088_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19088_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19088_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19088_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 19090...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19090_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19090_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19090_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19090_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19090_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19090_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 19093...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19093_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19093_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19093_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19093_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19093_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19093_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 19140...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19140_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19140_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19140_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19140_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19140_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19140_Sixth_5_min.csv\n",
      "\n",
      "Processing NSR subject 19830...\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19830_First_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19830_Second_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19830_Third_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19830_Fourth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19830_Fifth_5_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_17apr\\NSR_19830_Sixth_5_min.csv\n"
     ]
    }
   ],
   "source": [
    "# Process NSR data (normal order => 1st is earliest 5 min)\n",
    "for subj_id, seg_list in nsr_segments.items():\n",
    "    print(f\"\\nProcessing NSR subject {subj_id}...\")\n",
    "    # seg_list[0] = first 5 min, seg_list[1] = second 5 min, ...\n",
    "    for i in range(6):\n",
    "        segment_label = f\"NSR_{subj_id}_{label_map[i]}_5_min\"  # e.g. \"First_5_min\"\n",
    "        ecg_signal = seg_list[i]\n",
    "\n",
    "        denoised_signal = denoise_signal(ecg_signal, 'rbio1.5', 9, 1 , 7)\n",
    "        # 1) Detect R-peaks\n",
    "        r_peaks = r_peak_finder(denoised_signal)\n",
    "        # 2) Compute HRV\n",
    "        feats = compute_hrv_features(r_peaks, fs=128)\n",
    "        # 3) Build CSV file name, e.g. \"NSR_SubjectX_First_5_min.csv\"\n",
    "        csv_filename = f\"{segment_label}.csv\"\n",
    "        csv_path = os.path.join(output_dir_nsr, csv_filename)\n",
    "        # 4) Save\n",
    "        save_hrv_to_csv(feats, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6edcab-71a0-4bd4-a08d-04946c35652a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
