{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378a23a1-bd96-4330-9fa8-e1384b742b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.signal import medfilt\n",
    "import pywt\n",
    "from ecgdetectors import Detectors\n",
    "from scipy.signal import resample_poly\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5964c038-dd15-4d57-841a-543d5b0392d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsr_data = ['./data/nsrdb/16265',\n",
    " './data/nsrdb/16272',\n",
    " './data/nsrdb/16273',\n",
    " './data/nsrdb/16420',\n",
    " './data/nsrdb/16483',\n",
    " './data/nsrdb/16539',\n",
    " './data/nsrdb/16773',\n",
    " './data/nsrdb/16786',\n",
    " './data/nsrdb/16795',\n",
    " './data/nsrdb/17052',\n",
    " './data/nsrdb/17453',\n",
    " './data/nsrdb/18177',\n",
    " './data/nsrdb/18184',\n",
    " './data/nsrdb/19088',\n",
    " './data/nsrdb/19090',\n",
    " './data/nsrdb/19093',\n",
    " './data/nsrdb/19140',\n",
    " './data/nsrdb/19830']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8313382-d767-4abb-a3af-88a857af0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_60min_and_segment(record_paths):\n",
    "    \"\"\"\n",
    "    Given a list of NSR record paths (e.g. './data/nsrdb/16265'),\n",
    "    1) Read the first 60 minutes of the ECG from each record\n",
    "    2) Segment that 60-min signal into six 10-min parts\n",
    "    3) Return a dictionary mapping record_name -> [segment1, segment2, ... segment6]\n",
    "       Each segment is a NumPy array of shape (num_samples_5min, num_channels).\n",
    "    \"\"\"\n",
    "    \n",
    "    # For 60 min, we have 60 * 60 = 3600 seconds. \n",
    "    # For 10 min, we have 10 * 60 = 600 seconds.\n",
    "    \n",
    "    first_60min_segments = {}\n",
    "    \n",
    "    for record_path in record_paths:\n",
    "        \n",
    "        # Extract record name from path\n",
    "        # e.g. record_path = \"./data/nsrdb/16265\" => record_name = \"16265\"\n",
    "        record_dir, record_name = os.path.split(record_path)\n",
    "      \n",
    "        print(f\"Processing {record_name} ...\")\n",
    "        \n",
    "        # We want the first 60 minutes => 3600 seconds => num_samples = 3600 * fs\n",
    "        fs = 128\n",
    "        num_samples_60min = int(60 * 60 * fs)\n",
    "        \n",
    "        # Read from sample 0 to sample 0+num_samples_30min\n",
    "        try:\n",
    "            rec = wfdb.rdrecord(record_path, sampfrom=0, sampto=num_samples_60min)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not read {record_path}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if rec.p_signal is None:\n",
    "            print(f\"[WARN] No signal found in {record_name}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        full_60min = rec.p_signal[:,0]\n",
    "        \n",
    "        # Segment the 60-min array into six 10-min parts\n",
    "        # Each 10-min part = 10 * 60 * fs samples\n",
    "        \n",
    "        samples_10min = int(10 * 60 * fs)  # 600 seconds * 128 => 38400 * 2\n",
    "        \n",
    "        # We can slice in 6 equal blocks\n",
    "        segments_10min = []\n",
    "        for i in range(6):\n",
    "            start_i = i * samples_10min\n",
    "            end_i = start_i + samples_10min\n",
    "            segment = full_60min[start_i:end_i]\n",
    "            segments_10min.append(segment)\n",
    "        \n",
    "        # Store in a dictionary\n",
    "        first_60min_segments[record_name] = segments_10min\n",
    "        print(f\"[OK] Extracted 6 segments of 10 min each from {record_name}.\")\n",
    "    \n",
    "    return first_60min_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4fb750f-1019-4980-bfda-896cd3a0a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_signal(X, dwt_transform, dlevels, cutoff_low, cutoff_high):\n",
    "    coeffs = pywt.wavedec(X, dwt_transform, level=dlevels)   # wavelet transform 'bior4.4'\n",
    "    # scale 0 to cutoff_low \n",
    "    for ca in range(0,cutoff_low):\n",
    "        coeffs[ca]=np.multiply(coeffs[ca],[0.0])\n",
    "    # scale cutoff_high to end\n",
    "    for ca in range(cutoff_high, len(coeffs)):\n",
    "        coeffs[ca]=np.multiply(coeffs[ca],[0.0])\n",
    "    Y = pywt.waverec(coeffs, dwt_transform) # inverse wavelet transform\n",
    "    return Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0381053-546f-4ee2-b3c7-30708d84e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_peak_finder(ecg_sig):\n",
    "    BASIC_SRATE = 128\n",
    "    signal_pad_samples = 10\n",
    "    signal_pad = np.zeros(signal_pad_samples)  # Pad to help detect early peaks\n",
    "    scd_30_denoised_ = ...  # Your denoised 60-min ECG segment\n",
    "    \n",
    "    # Initialize the detectors at the given sampling rate\n",
    "    detector_obj = Detectors(BASIC_SRATE)\n",
    "    \n",
    "    # Dictionary of detector functions\n",
    "    detectors = {\n",
    "        'pan_tompkins_detector': detector_obj.pan_tompkins_detector,\n",
    "        'hamilton_detector': detector_obj.hamilton_detector,\n",
    "        'christov_detector': detector_obj.christov_detector,\n",
    "        'engzee_detector': detector_obj.engzee_detector,\n",
    "        'swt_detector': detector_obj.swt_detector,\n",
    "        'two_average_detector': detector_obj.two_average_detector,\n",
    "    }\n",
    "    \n",
    "    r_peaks = np.array(detector_obj.engzee_detector(np.hstack((signal_pad, ecg_sig)) )) - signal_pad_samples\n",
    "    return r_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a2c4139-7c01-46c5-88a4-6a8b4cf904bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hrv_features(r_peaks, fs=128):\n",
    "    \"\"\"\n",
    "    Time-domain HRV features from R-peaks.\n",
    "    Returns a dict with:\n",
    "      MeanRR, RMSDD, pNN50, SDRR, CVRR, NN50, MinRR, MaxRR\n",
    "    \"\"\"\n",
    "    features = {\n",
    "        'MeanRR': 0.0,\n",
    "        'RMSDD': 0.0,\n",
    "        'MADRR': 0.0,\n",
    "        'MCVNN': 0.0,\n",
    "        'pNN20': 0.0,\n",
    "        'pNN50': 0.0,\n",
    "        'SDRR': 0.0,\n",
    "        'CVRR': 0.0,\n",
    "        'NN20': 0,\n",
    "        'NN50': 0,\n",
    "        'MinRR': 0.0,\n",
    "        'MaxRR': 0.0\n",
    "    }\n",
    "\n",
    "    rr_samples = np.diff(r_peaks)\n",
    "    rr_ms = (rr_samples / fs) * 1000.0  # convert to ms\n",
    "\n",
    "    mean_rr = np.mean(rr_ms)\n",
    "    sdrr = np.std(rr_ms, ddof=1) if len(rr_ms) > 1 else 0.0\n",
    "    min_rr = np.min(rr_ms)\n",
    "    max_rr = np.max(rr_ms)\n",
    "\n",
    "    rr_diffs = np.diff(rr_ms)\n",
    "    rmssd = np.sqrt(np.mean(rr_diffs**2)) if len(rr_diffs) > 0 else 0.0\n",
    "    nn50 = np.sum(np.abs(rr_diffs) > 50)\n",
    "    pnn50 = (nn50 / len(rr_diffs)) * 100 if len(rr_diffs) > 0 else 0.0\n",
    "    nn20 = np.sum(np.abs(rr_diffs) > 20)\n",
    "    pnn20 = (nn20 / len(rr_diffs)) * 100 if len(rr_diffs) > 0 else 0.0\n",
    "    cvrr = (sdrr / mean_rr * 100.0) if mean_rr else 0.0\n",
    "    madrr = np.median(np.abs(rr_ms - np.median(rr_ms)))\n",
    "    mcvnn = np.abs(rr_samples).mean()\n",
    "\n",
    "    features['MeanRR'] = mean_rr / 1000.0\n",
    "    features['RMSDD'] = rmssd / 1000.0\n",
    "    # new \n",
    "    features['MADRR'] = madrr / 1000.0\n",
    "    features['MCVNN'] = mcvnn / 1000.0 \n",
    "    features['pNN20'] = pnn20 / 1000.0\n",
    "    \n",
    "    \n",
    "    features['pNN50'] = pnn50 / 1000.0\n",
    "    features['SDRR'] = sdrr / 1000.0\n",
    "    features['CVRR'] = cvrr / 1000.0 \n",
    "    # new\n",
    "    features['NN20'] = nn20 / 1000.0\n",
    "    \n",
    "    features['NN50'] = nn50 / 1000.0\n",
    "    features['MinRR'] = min_rr / 1000.0 \n",
    "    features['MaxRR'] = max_rr / 1000.0\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b45ead94-b2dd-44c9-981f-bfd996a5b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = [\"First\", \"Second\", \"Third\", \"Fourth\", \"Fifth\", \"Sixth\"]\n",
    "\n",
    "def save_hrv_to_csv(features_dict, csv_path):\n",
    "    \"\"\"\n",
    "    Save a single row of features_dict into a CSV at csv_path.\n",
    "    Overwrites if file exists.\n",
    "    Columns: [MeanRR, RMSDD, MADRR, MCVNN, pNN20, pNN50, SDRR, CVRR, NN20, NN50, MinRR, MaxRR]\n",
    "    \"\"\"\n",
    "    columns = [\"MeanRR\", \"RMSDD\", \"MADRR\", \"MCVNN\", \"pNN20\", \"pNN50\", \"SDRR\", \"CVRR\", \"NN20\", \"NN50\", \"MinRR\", \"MaxRR\"]\n",
    "    with open(csv_path, mode='w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=columns)\n",
    "        writer.writeheader()\n",
    "        writer.writerow({col: features_dict[col] for col in columns})\n",
    "    print(f\"  -> Saved HRV features to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36051ddb-3cb0-46df-93a1-172a42e5e268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 16265 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 16265.\n",
      "Processing 16272 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 16272.\n",
      "Processing 16273 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 16273.\n",
      "Processing 16420 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 16420.\n",
      "Processing 16483 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 16483.\n",
      "Processing 16539 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 16539.\n",
      "Processing 16773 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 16773.\n",
      "Processing 16786 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 16786.\n",
      "Processing 16795 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 16795.\n",
      "Processing 17052 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 17052.\n",
      "Processing 17453 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 17453.\n",
      "Processing 18177 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 18177.\n",
      "Processing 18184 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 18184.\n",
      "Processing 19088 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 19088.\n",
      "Processing 19090 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 19090.\n",
      "Processing 19093 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 19093.\n",
      "Processing 19140 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 19140.\n",
      "Processing 19830 ...\n",
      "[OK] Extracted 6 segments of 10 min each from 19830.\n"
     ]
    }
   ],
   "source": [
    "nsr_segments  = extract_first_60min_and_segment(nsr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8020d1d6-7cb0-40dc-92cf-4550a54210ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'16265': [array([-0.165, -0.155, -0.195, ..., -0.365,  1.475,  2.795]),\n",
       "  array([ 2.935,  2.535,  0.605, ..., -0.145, -0.145, -0.135]),\n",
       "  array([-0.175, -0.135, -0.175, ..., -0.135, -0.175, -0.175]),\n",
       "  array([-0.155, -0.115, -0.155, ..., -0.765, -0.855, -0.005]),\n",
       "  array([ 1.865,  2.825,  2.685, ..., -0.185, -0.205, -0.185]),\n",
       "  array([-0.165, -0.185, -0.165, ..., -0.105, -0.135, -0.065])],\n",
       " '16272': [array([-0.185, -0.215, -0.215, ..., -0.085, -0.075, -0.055]),\n",
       "  array([-0.085, -0.085, -0.095, ..., -0.075, -0.065, -0.065]),\n",
       "  array([-0.075, -0.075, -0.085, ..., -0.045, -0.045, -0.055]),\n",
       "  array([-0.035, -0.045, -0.085, ..., -0.105, -0.105, -0.095]),\n",
       "  array([-0.105, -0.095, -0.115, ..., -0.095, -0.055, -0.065]),\n",
       "  array([-0.095, -0.065, -0.105, ..., -0.105, -0.105, -0.095])],\n",
       " '16273': [array([-0.305, -0.265, -0.245, ...,  1.485,  2.755,  3.225]),\n",
       "  array([ 1.925,  0.335, -0.205, ..., -0.165, -0.175, -0.175]),\n",
       "  array([-0.185, -0.185, -0.185, ...,  0.485,  0.395,  0.365]),\n",
       "  array([ 0.325,  0.325,  0.335, ..., -0.125, -0.105, -0.095]),\n",
       "  array([-0.065, -0.395, -0.535, ..., -0.345, -0.335, -0.325]),\n",
       "  array([-0.305, -0.305, -0.295, ..., -0.165, -0.155, -0.145])],\n",
       " '16420': [array([-0.095, -0.085, -0.085, ..., -0.115, -0.135, -0.135]),\n",
       "  array([-0.135, -0.135, -0.145, ...,  0.025, -0.015, -0.015]),\n",
       "  array([-0.035, -0.065, -0.085, ..., -0.075, -0.115, -0.095]),\n",
       "  array([-0.085, -0.115, -0.095, ..., -0.105, -0.095, -0.115]),\n",
       "  array([-0.095, -0.105, -0.105, ..., -0.085, -0.085, -0.075]),\n",
       "  array([-0.075, -0.095, -0.085, ..., -0.145, -0.175, -0.135])],\n",
       " '16483': [array([-0.075, -0.165, -0.225, ...,  0.315, -0.495, -0.645]),\n",
       "  array([-0.195, -0.125, -0.115, ..., -0.195, -0.155, -0.185]),\n",
       "  array([-0.195, -0.205, -0.105, ..., -0.045,  0.035,  0.165]),\n",
       "  array([ 0.125,  0.055,  0.035, ...,  0.105,  0.025, -0.035]),\n",
       "  array([-0.085, -0.085, -0.085, ..., -0.035, -0.045, -0.165]),\n",
       "  array([-0.075, -0.045, -0.115, ...,  0.195,  0.095,  0.025])],\n",
       " '16539': [array([-0.185, -0.155, -0.145, ..., -0.065, -0.075, -0.095]),\n",
       "  array([-0.065, -0.095, -0.095, ..., -0.265, -0.335, -0.335]),\n",
       "  array([-0.355, -0.265, -0.275, ..., -0.115, -0.165, -0.125]),\n",
       "  array([-0.165, -0.045, -0.095, ..., -0.135, -0.205, -0.155]),\n",
       "  array([-0.185, -0.165, -0.155, ...,  0.115,  0.145,  0.185]),\n",
       "  array([ 0.215,  0.245,  0.285, ..., -0.115, -0.125, -0.135])],\n",
       " '16773': [array([-0.355, -0.355, -0.345, ..., -0.265, -0.255, -0.295]),\n",
       "  array([-0.295, -0.295, -0.295, ...,  2.255,  2.945,  2.705]),\n",
       "  array([ 0.195, -0.795, -0.755, ..., -0.235, -0.235, -0.235]),\n",
       "  array([-0.235, -0.245, -0.225, ..., -0.275, -0.275, -0.295]),\n",
       "  array([-0.295, -0.285, -0.275, ..., -0.195, -0.245, -0.185]),\n",
       "  array([-0.185, -0.215, -0.205, ...,  0.565,  0.525,  0.405])],\n",
       " '16786': [array([-0.275, -0.245, -0.285, ..., -0.135, -0.115, -0.105]),\n",
       "  array([-0.075, -0.025, -0.045, ..., -0.715, -0.345,  1.235]),\n",
       "  array([2.425, 2.945, 1.655, ..., 0.305, 0.205, 0.075]),\n",
       "  array([ 0.005, -0.055, -0.105, ...,  0.075,  0.155,  0.215]),\n",
       "  array([ 0.255,  0.295,  0.315, ..., -0.145, -0.085, -0.075]),\n",
       "  array([-0.045,  0.025,  0.085, ..., -0.225, -0.135, -0.215])],\n",
       " '16795': [array([ 0.125,  0.005,  0.025, ..., -0.265, -0.285, -0.265]),\n",
       "  array([-0.145,  0.065,  0.345, ..., -0.145, -0.155, -0.125]),\n",
       "  array([-0.115, -0.125, -0.095, ..., -0.135, -0.155, -0.145]),\n",
       "  array([-0.145, -0.165, -0.135, ..., -0.135, -0.165, -0.145]),\n",
       "  array([-0.155, -0.165, -0.165, ..., -0.075, -0.085, -0.085]),\n",
       "  array([-0.085, -0.085, -0.065, ..., -0.115, -0.085, -0.035])],\n",
       " '17052': [array([-0.035, -0.015, -0.045, ..., -0.145, -0.195, -0.155]),\n",
       "  array([-0.085, -0.045, -0.125, ..., -0.055, -0.045, -0.035]),\n",
       "  array([-0.025,  0.005,  0.255, ..., -0.145, -0.135, -0.125]),\n",
       "  array([-0.135, -0.145, -0.125, ..., -0.085, -0.115, -0.085]),\n",
       "  array([-0.005, -0.135, -0.115, ..., -0.015,  0.025,  0.095]),\n",
       "  array([ 0.375,  1.035,  1.425, ..., -0.105, -0.105, -0.095])],\n",
       " '17453': [array([ 0.525,  0.695,  0.475, ..., -0.075, -0.075, -0.045]),\n",
       "  array([-0.175,  0.025,  0.035, ..., -0.145, -0.145, -0.135]),\n",
       "  array([-0.095, -0.105, -0.065, ..., -0.195, -0.195, -0.185]),\n",
       "  array([-0.155, -0.165, -0.165, ..., -0.135, -0.175, -0.165]),\n",
       "  array([-0.165, -0.165, -0.195, ..., -0.095, -0.045, -0.005]),\n",
       "  array([-0.075, -0.115, -0.125, ..., -0.245, -0.245, -0.185])],\n",
       " '18177': [array([-0.215, -0.195, -0.185, ..., -0.105, -0.155, -0.155]),\n",
       "  array([-0.235, -0.305, -0.345, ...,  0.105,  0.095,  0.105]),\n",
       "  array([ 0.085,  0.055, -0.025, ..., -0.125, -0.035,  0.055]),\n",
       "  array([0.075, 0.035, 0.135, ..., 0.275, 0.275, 0.265]),\n",
       "  array([ 0.175,  0.095,  0.045, ...,  0.085,  0.005, -0.075]),\n",
       "  array([-0.135, -0.145, -0.225, ..., -0.115, -0.155, -0.145])],\n",
       " '18184': [array([-0.325, -0.395, -0.255, ..., -0.115, -0.095,  0.085]),\n",
       "  array([ 0.055,  0.265,  0.055, ..., -0.155, -0.175, -0.155]),\n",
       "  array([-0.215, -0.185, -0.175, ..., -0.225, -0.195, -0.255]),\n",
       "  array([-0.405,  0.225,  1.425, ..., -0.085, -0.055, -0.075]),\n",
       "  array([-0.045, -0.065, -0.075, ..., -0.225, -0.215, -0.225]),\n",
       "  array([-0.265, -0.265, -0.165, ...,  0.155,  0.175,  0.175])],\n",
       " '19088': [array([ 0.365,  0.365,  0.355, ..., -0.105, -0.125, -0.115]),\n",
       "  array([-0.115, -0.125, -0.135, ..., -0.205, -0.105, -0.155]),\n",
       "  array([-0.135,  0.275,  0.805, ..., -0.105, -0.085, -0.075]),\n",
       "  array([-0.075, -0.055, -0.055, ..., -0.175, -0.155, -0.165]),\n",
       "  array([-0.155, -0.155, -0.115, ..., -0.165, -0.145, -0.165]),\n",
       "  array([-0.165, -0.165, -0.055, ..., -0.035, -0.035, -0.045])],\n",
       " '19090': [array([ 0.165,  0.155,  0.155, ..., -0.125, -0.115, -0.105]),\n",
       "  array([-0.095, -0.075, -0.075, ..., -0.085, -0.095, -0.105]),\n",
       "  array([-0.085, -0.065, -0.095, ..., -0.005,  0.025,  0.005]),\n",
       "  array([ 0.085,  0.115,  0.055, ..., -0.135, -0.135, -0.165]),\n",
       "  array([-0.135, -0.145, -0.155, ..., -0.105, -0.045, -0.035]),\n",
       "  array([-0.035,  0.025,  0.065, ..., -0.005,  0.025,  0.055])],\n",
       " '19093': [array([ 0.675,  0.665,  0.655, ..., -0.225, -0.235, -0.225]),\n",
       "  array([-0.225, -0.215, -0.215, ..., -0.225, -0.285, -0.265]),\n",
       "  array([-0.255, -0.275, -0.265, ..., -0.195, -0.195, -0.185]),\n",
       "  array([-0.155, -0.085, -0.065, ...,  0.765,  0.605,  0.445]),\n",
       "  array([ 0.245,  0.065, -0.105, ..., -0.335, -0.335,  0.335]),\n",
       "  array([ 1.835,  2.335, -0.405, ...,  0.135,  0.155,  0.215])],\n",
       " '19140': [array([ 0.255,  0.245,  0.235, ..., -0.015,  0.025,  0.105]),\n",
       "  array([ 0.125,  0.155,  0.185, ..., -0.165, -0.175, -0.175]),\n",
       "  array([-0.175, -0.205, -0.205, ...,  0.035,  0.125,  0.195]),\n",
       "  array([ 0.185,  0.235,  0.275, ..., -0.075, -0.095, -0.145]),\n",
       "  array([-0.175, -0.195, -0.175, ...,  0.355,  0.395,  0.425]),\n",
       "  array([ 0.435,  0.415,  0.365, ...,  0.165,  0.065, -0.015])],\n",
       " '19830': [array([-0.435, -0.435, -0.415, ..., -0.105, -0.115, -0.115]),\n",
       "  array([-0.115, -0.115, -0.105, ..., -0.215, -0.235, -0.225]),\n",
       "  array([-0.205, -0.225, -0.235, ..., -0.165, -0.165, -0.155]),\n",
       "  array([-0.135, -0.135, -0.115, ..., -0.115, -0.075, -0.115]),\n",
       "  array([-0.115, -0.105, -0.125, ..., -0.115, -0.735, -0.945]),\n",
       "  array([-1.045, -1.095, -1.125, ..., -0.175, -0.145, -0.035])]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsr_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f639334-bddc-4642-954c-61340cdfbc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_nsr = \"NSR_Features_CSV_1h_10min_segments\"\n",
    "os.makedirs(output_dir_nsr, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "096bbb8c-5363-48f8-b2e3-147bc41d9d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing NSR subject 16265...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16265_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16265_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16265_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16265_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16265_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16265_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 16272...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16272_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16272_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16272_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16272_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16272_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16272_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 16273...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16273_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16273_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16273_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16273_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16273_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16273_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 16420...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16420_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16420_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16420_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16420_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16420_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16420_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 16483...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16483_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16483_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16483_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16483_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16483_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16483_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 16539...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16539_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16539_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16539_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16539_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16539_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16539_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 16773...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16773_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16773_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16773_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16773_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16773_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16773_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 16786...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16786_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16786_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16786_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16786_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16786_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16786_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 16795...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16795_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16795_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16795_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16795_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16795_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_16795_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 17052...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_17052_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_17052_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_17052_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_17052_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_17052_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_17052_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 17453...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_17453_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_17453_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_17453_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_17453_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_17453_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_17453_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 18177...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_18177_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_18177_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_18177_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_18177_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_18177_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_18177_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 18184...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_18184_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_18184_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_18184_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_18184_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_18184_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_18184_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 19088...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19088_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19088_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19088_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19088_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19088_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19088_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 19090...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19090_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19090_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19090_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19090_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19090_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19090_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 19093...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19093_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19093_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19093_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19093_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19093_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19093_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 19140...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19140_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19140_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19140_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19140_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19140_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19140_Sixth_10_min.csv\n",
      "\n",
      "Processing NSR subject 19830...\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19830_First_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19830_Second_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19830_Third_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19830_Fourth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19830_Fifth_10_min.csv\n",
      "  -> Saved HRV features to NSR_Features_CSV_1h_10min_segments\\NSR_19830_Sixth_10_min.csv\n"
     ]
    }
   ],
   "source": [
    "# Process NSR data (normal order => 1st is earliest 10 min)\n",
    "for subj_id, seg_list in nsr_segments.items():\n",
    "    print(f\"\\nProcessing NSR subject {subj_id}...\")\n",
    "    # seg_list[0] = first 10 min, seg_list[1] = second 10 min, ...\n",
    "    for i in range(6):\n",
    "        segment_label = f\"NSR_{subj_id}_{label_map[i]}_10_min\"  # e.g. \"First_10_min\"\n",
    "        ecg_signal = seg_list[i]\n",
    "\n",
    "        denoised_signal = denoise_signal(ecg_signal, 'rbio1.5', 9, 1 , 7)\n",
    "        # 1) Detect R-peaks\n",
    "        r_peaks = r_peak_finder(denoised_signal)\n",
    "        # 2) Compute HRV\n",
    "        feats = compute_hrv_features(r_peaks, fs=128)\n",
    "        # 3) Build CSV file name, e.g. \"NSR_SubjectX_First_10_min.csv\"\n",
    "        csv_filename = f\"{segment_label}.csv\"\n",
    "        csv_path = os.path.join(output_dir_nsr, csv_filename)\n",
    "        # 4) Save\n",
    "        save_hrv_to_csv(feats, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f48e2a-9cdd-4fed-9899-6d68c0951dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
